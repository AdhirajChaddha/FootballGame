{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10 ML Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdhirajChaddha/FootballGame/blob/master/CIFAR10_ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8chO3HzFOAQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "025e0f42-e242-4bfa-bf6e-0b13c81da34d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "print(\"Training on GPU: \", train_on_gpu)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU:  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpH4yPHQFdFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "acdc7166-0c9d-46bd-f18c-b2107eb7bf7d"
      },
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "batchSize = 20\n",
        "validationSize = 0.2\n",
        "\n",
        "transformsTrain = transforms.Compose([\n",
        "#     transforms.Pad(1),\n",
        "#     transforms.RandomGrayscale(),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(10),\n",
        "    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "transformsTest = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "\n",
        "# Download training and testing data\n",
        "trainingData = datasets.CIFAR10('data', train=True, \n",
        "                                transform=transformsTrain, download=True)\n",
        "\n",
        "testingData = datasets.CIFAR10('data', train=False, \n",
        "                                transform=transformsTest, download=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIjJLrpgGDUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Devide the data int0 training and validation sets\n",
        "length = len(trainingData)\n",
        "indices = list(range(length))\n",
        "np.random.shuffle(indices)\n",
        "split = (int)(length*validationSize)\n",
        "train_idx, val_idx = idices[:split], indices[split:]\n",
        "\n",
        "# Put the inices into the samplers for making dataloader\n",
        "trainSampler = SubsetRandomSampler(train_idx)\n",
        "validationSampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "# Create the data loaders\n",
        "trainLoader = torch.utils.data.DataLoader(trainingData, batch_size=batchSize,\n",
        "    sampler=trainSampler)\n",
        "valLoader = torch.utils.data.DataLoader(trainingData, batch_size=batchSize,\n",
        "    sampler=validationSampler)\n",
        "testLoader = torch.utils.data.DataLoader(testingData, batch_size=batchSize)\n",
        "\n",
        "# specify the image classes\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHXkt5I4UUsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# helper function to un-normalize and display an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWfDveBSVWe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "a5e4dd46-9520-41dd-f0d9-ad048840a799"
      },
      "source": [
        "dataiter = iter(trainLoader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "imshow(images.cpu()[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqXkF4mUkl8kUv8HNozmAN9HEGQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLxOF6D6Vxlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "    \n",
        "    self.maxPool = nn.MaxPool2d(2, 2)\n",
        "    \n",
        "    self.fc1 = nn.Linear(4*4*64, 500)\n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "    \n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.maxPool(x)\n",
        "    \n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.maxPool(x)\n",
        "    \n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = self.maxPool(x)\n",
        "    \n",
        "    x = x.view(-1, 4*4*64)\n",
        "    \n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc2(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNkat3c7YPSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN()\n",
        "\n",
        "if train_on_gpu:\n",
        "  model.cuda()\n",
        "  \n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "LossFunction = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnaz4s_8YRI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "8bca0a01-0487-4ea0-fe86-fdfcc0f9e0a8"
      },
      "source": [
        "epochs = 30\n",
        "\n",
        "# Set the minimum validation loss achieved to infinity innitailly \n",
        "minimumValidationLoss = np.Inf\n",
        "  \n",
        "for e in range(epochs):\n",
        "  trainLoss = 0.0\n",
        "  validationLoss = 0.0\n",
        "  \n",
        "  ################# \n",
        "  # Training Loop #\n",
        "  #################\n",
        "  model.train()\n",
        "  for images, labels in trainLoader:\n",
        "    if train_on_gpu:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    # Set gradients to zero from last step\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Get output, calculate loss, backpropogate and then update the weights\n",
        "    output = model(images) # output\n",
        "    loss = LossFunction(output, labels) # loss calcluation \n",
        "    loss.backward() # backpropogation\n",
        "    optimizer.step() # updating weights\n",
        "    \n",
        "    # Get the total loss over the batch by multiplying loss with batch size\n",
        "    trainLoss += loss.item()*images.size(0) \n",
        "    \n",
        "  ###################\n",
        "  # Validation Loop #\n",
        "  ###################\n",
        "  model.eval()\n",
        "  for images, labels in valLoader:\n",
        "    if train_on_gpu:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    \n",
        "    # Get output, calculate loss, backpropogate and then update the weights\n",
        "    output = model(images) # output\n",
        "    loss = LossFunction(output, labels) # loss calcluation \n",
        "    \n",
        "    # Get the total loss over the batch by multiplying loss with batch size\n",
        "    validationLoss += loss.item()*images.size(0) \n",
        "    \n",
        "    \n",
        "  # Getting the average losses in trainin gand validation loop\n",
        "  avgTrainLoss = trainLoss/len(trainLoader.dataset)  \n",
        "  avgValLoss = validationLoss/len(valLoader.dataset)\n",
        "  \n",
        "  print(\"Epoch: \", e+1, '\\tTraining Loss: ', \n",
        "        avgTrainLoss, '\\tValidation Loss: ', avgValLoss)\n",
        "  \n",
        "  # Saving the model and setting new minValidationLoss if current model has \n",
        "  # lower loss that the previous one saved\n",
        "  if avgValLoss <= minimumValidationLoss:\n",
        "    print(\"Saving model \\t Validation loss gone from: \", minimumValidationLoss,\n",
        "         \" to: \", avgValLoss)\n",
        "    torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "    minimumValidationLoss = avgValLoss"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1 \tTraining Loss:  0.4575807207107544 \tValidation Loss:  1.802000500202179\n",
            "Saving model \t Validation loss gone from:  inf  to:  1.802000500202179\n",
            "Epoch:  2 \tTraining Loss:  0.43020141739845275 \tValidation Loss:  1.6362512901306152\n",
            "Saving model \t Validation loss gone from:  1.802000500202179  to:  1.6362512901306152\n",
            "Epoch:  3 \tTraining Loss:  0.39675560336112975 \tValidation Loss:  1.526107603931427\n",
            "Saving model \t Validation loss gone from:  1.6362512901306152  to:  1.526107603931427\n",
            "Epoch:  4 \tTraining Loss:  0.3701688827037811 \tValidation Loss:  1.443469809627533\n",
            "Saving model \t Validation loss gone from:  1.526107603931427  to:  1.443469809627533\n",
            "Epoch:  5 \tTraining Loss:  0.34376062479019165 \tValidation Loss:  1.3265503953456879\n",
            "Saving model \t Validation loss gone from:  1.443469809627533  to:  1.3265503953456879\n",
            "Epoch:  6 \tTraining Loss:  0.32425142102241516 \tValidation Loss:  1.2664010108232497\n",
            "Saving model \t Validation loss gone from:  1.3265503953456879  to:  1.2664010108232497\n",
            "Epoch:  7 \tTraining Loss:  0.3104808688402176 \tValidation Loss:  1.2119762412071229\n",
            "Saving model \t Validation loss gone from:  1.2664010108232497  to:  1.2119762412071229\n",
            "Epoch:  8 \tTraining Loss:  0.3008548321723938 \tValidation Loss:  1.1631957408189773\n",
            "Saving model \t Validation loss gone from:  1.2119762412071229  to:  1.1631957408189773\n",
            "Epoch:  9 \tTraining Loss:  0.2891532680749893 \tValidation Loss:  1.156374349784851\n",
            "Saving model \t Validation loss gone from:  1.1631957408189773  to:  1.156374349784851\n",
            "Epoch:  10 \tTraining Loss:  0.2806488294839859 \tValidation Loss:  1.0999313391923904\n",
            "Saving model \t Validation loss gone from:  1.156374349784851  to:  1.0999313391923904\n",
            "Epoch:  11 \tTraining Loss:  0.2702796636343002 \tValidation Loss:  1.1169540730714798\n",
            "Epoch:  12 \tTraining Loss:  0.26217739799022677 \tValidation Loss:  1.0648990714550017\n",
            "Saving model \t Validation loss gone from:  1.0999313391923904  to:  1.0648990714550017\n",
            "Epoch:  13 \tTraining Loss:  0.2546516068458557 \tValidation Loss:  1.0285280458211898\n",
            "Saving model \t Validation loss gone from:  1.0648990714550017  to:  1.0285280458211898\n",
            "Epoch:  14 \tTraining Loss:  0.2478680295944214 \tValidation Loss:  0.9874533453702926\n",
            "Saving model \t Validation loss gone from:  1.0285280458211898  to:  0.9874533453702926\n",
            "Epoch:  15 \tTraining Loss:  0.24033786759376527 \tValidation Loss:  0.9766109453678131\n",
            "Saving model \t Validation loss gone from:  0.9874533453702926  to:  0.9766109453678131\n",
            "Epoch:  16 \tTraining Loss:  0.2324142326116562 \tValidation Loss:  0.9462075533986092\n",
            "Saving model \t Validation loss gone from:  0.9766109453678131  to:  0.9462075533986092\n",
            "Epoch:  17 \tTraining Loss:  0.2249465665102005 \tValidation Loss:  0.9671057263612747\n",
            "Epoch:  18 \tTraining Loss:  0.2200911601781845 \tValidation Loss:  0.917515571475029\n",
            "Saving model \t Validation loss gone from:  0.9462075533986092  to:  0.917515571475029\n",
            "Epoch:  19 \tTraining Loss:  0.211694347512722 \tValidation Loss:  0.8872129442691803\n",
            "Saving model \t Validation loss gone from:  0.917515571475029  to:  0.8872129442691803\n",
            "Epoch:  20 \tTraining Loss:  0.20424973472356797 \tValidation Loss:  0.8964299245357513\n",
            "Epoch:  21 \tTraining Loss:  0.19907908036708832 \tValidation Loss:  0.8703223660230637\n",
            "Saving model \t Validation loss gone from:  0.8872129442691803  to:  0.8703223660230637\n",
            "Epoch:  22 \tTraining Loss:  0.19196101001501084 \tValidation Loss:  0.8786960491299629\n",
            "Epoch:  23 \tTraining Loss:  0.18426399692296982 \tValidation Loss:  0.8375091231465339\n",
            "Saving model \t Validation loss gone from:  0.8703223660230637  to:  0.8375091231465339\n",
            "Epoch:  24 \tTraining Loss:  0.1783649874329567 \tValidation Loss:  0.8370985775709152\n",
            "Saving model \t Validation loss gone from:  0.8375091231465339  to:  0.8370985775709152\n",
            "Epoch:  25 \tTraining Loss:  0.17207565764188767 \tValidation Loss:  0.8287658034563065\n",
            "Saving model \t Validation loss gone from:  0.8370985775709152  to:  0.8287658034563065\n",
            "Epoch:  26 \tTraining Loss:  0.1647487451672554 \tValidation Loss:  0.8075905793428421\n",
            "Saving model \t Validation loss gone from:  0.8287658034563065  to:  0.8075905793428421\n",
            "Epoch:  27 \tTraining Loss:  0.15824413474798202 \tValidation Loss:  0.8013477494359016\n",
            "Saving model \t Validation loss gone from:  0.8075905793428421  to:  0.8013477494359016\n",
            "Epoch:  28 \tTraining Loss:  0.15217821539640428 \tValidation Loss:  0.8052987455964088\n",
            "Epoch:  29 \tTraining Loss:  0.14627602318525315 \tValidation Loss:  0.8081011584401131\n",
            "Epoch:  30 \tTraining Loss:  0.13800681202411652 \tValidation Loss:  0.8094398331046104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgheqFxKeE5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22917828-a59e-4e03-e336-6cd69555c4a1"
      },
      "source": [
        "model.load_state_dict(torch.load('model_cifar.pt'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0qIeGxqg5sv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2148fc31-85e0-423b-9fd7-0bedf4bc78da"
      },
      "source": [
        "testLoss = 0.0\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "for images, labels in testLoader:\n",
        "  if train_on_gpu:\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "      \n",
        "  out = model(images)\n",
        "  loss = LossFunction(out, labels)\n",
        "  \n",
        "  testLoss += loss.item()*images.size(0)\n",
        "  \n",
        "  _, pred = torch.max(out, 1)    \n",
        "  # compare predictions to true label\n",
        "  correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "  correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "  # calculate test accuracy for each object class\n",
        "  for i in range(batchSize):\n",
        "    label = labels.data[i]\n",
        "    class_correct[label] += correct[i].item()\n",
        "    class_total[label] += 1\n",
        "  \n",
        "  \n",
        "testLoss = testLoss/len(testLoader.dataset)\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n",
        "\n",
        "print(\"Avg Loss is: \", testLoss)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of airplane: 69% (696/1000)\n",
            "Test Accuracy of automobile: 64% (640/1000)\n",
            "Test Accuracy of  bird: 48% (481/1000)\n",
            "Test Accuracy of   cat: 41% (412/1000)\n",
            "Test Accuracy of  deer: 51% (516/1000)\n",
            "Test Accuracy of   dog: 46% (465/1000)\n",
            "Test Accuracy of  frog: 80% (804/1000)\n",
            "Test Accuracy of horse: 67% (672/1000)\n",
            "Test Accuracy of  ship: 74% (740/1000)\n",
            "Test Accuracy of truck: 77% (772/1000)\n",
            "\n",
            "Test Accuracy (Overall): 61% (6198/10000)\n",
            "Avg Loss is:  1.0817258647084236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i715l2OQhd2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}